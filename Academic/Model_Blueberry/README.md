# ğŸ« Wild Blueberry Yield Prediction

This project implements a complete **machine learning pipeline** to predict the **yield of wild blueberries** ğŸ‡ based on agricultural, meteorological, and pollination data. It covers preprocessing, **dimensionality reduction (PCA)**, model training using **Random Forest Regressor**, and performance evaluation with visualizations ğŸ“Š.

---

## ğŸ“ Project Structure

â”œâ”€â”€ main.py # ğŸš€ Entry point to run the pipeline

â”œâ”€â”€ Data/ 

â”‚ â”œâ”€â”€ WildBlueberryPollinationSimulationData.csv

â”œâ”€â”€ src/

â”‚ â”œâ”€â”€ data_loader.py # ğŸ“¦ Functions for data loading

â”‚ â”œâ”€â”€ preprocessing.py # ğŸ§¹ Data cleaning and PCA transformation

â”‚ â””â”€â”€ model.py # ğŸ§  Model training, evaluation, and plots

â”œâ”€â”€ requirements.txt

â””â”€â”€ README.md # ğŸ“„ Project documentation


---

## ğŸ“Š Dataset

- **ğŸ“Œ Source:** Kaggle â€“ *Wild Blueberry Yield Prediction Dataset*
- **ğŸ§¬ Features:**

  - **Pollinators:** `honeybee`, `bumbles`, `andrena`, `osmia` ğŸ  
  - **Weather Metrics:** Max/Min/Avg Upper & Lower Temps ğŸŒ¡ï¸, Rainfall Days ğŸŒ§ï¸  
  - **Plant Data:** `clonesize`, `fruitset`, `fruitmass`, `seeds` ğŸŒ±  
  - **ğŸ¯ Target:** `yield`

- **ğŸ§¾ Shape:** `777 samples`, `17 features` (after cleaning)

---

## ğŸ§° Requirements

- Python 3.x  
- pandas  
- numpy  
- scikit-learn  
- seaborn  
- matplotlib  

```bash
pip install pandas numpy scikit-learn seaborn matplotlib
```
---
### â–¶ï¸ Usage
1. Update DATA_PATH in main.py:
```python
DATA_PATH = 'path_to_data.csv'
```
2. Run the pipeline:
```bash
python main.py
```
---

### ğŸ”„ Pipeline Overview

-ğŸ“¥ Data Loading: Load and clean dataset, remove irrelevant columns

-ğŸ§ª Data Splitting: 70:30 train-test split
---

### âš™ï¸ Feature Engineering (PCA):

-PCA on fruit-related features: fruitset, fruitmass, seeds

-PCA on temperature-related features

-PCA on rainfall-related features

ğŸŒ² Model Training: Random Forest Regressor with hyperparameter tuning via RandomizedSearchCV

## ğŸ“ˆ Evaluation:

-Training MSE and RÂ²

-Feature importance visualization

-Actual vs Predicted scatter plot

### ğŸ Results
## âœ… Best Hyperparameters
```json
{
  "n_estimators": 200,
  "min_samples_split": 2,
  "min_samples_leaf": 1,
  "max_depth": 10
}
```
## ğŸ“‰ Model Performance

```yaml
Mean Squared Error (Training): 5196.56
RÂ² (Training): 0.997
```

### ğŸŒŸ Key Features by Importance
-clonesize

-pca_feature (fruit metrics)

-pca_temperature (weather metrics)

-pca_rain (rainfall metrics)

---

### ğŸ–¼ï¸ Visual Outputs
ğŸ“Š Feature Importance Plot â€“ Shows key contributors to prediction

ğŸ”µ Actual vs Predicted Plot â€“ Highlights prediction accuracy

